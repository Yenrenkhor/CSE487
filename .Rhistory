library(rtweet)
install.packages("rtweet")
library(dplyr)
library(stringr)
library(maps)
library(ggplot2)
create_token(
app = "www.twitter.com",
consumer_key = "BoWXRggutLO4NqoCNv3GAPR06",
consumer_secret = "oYgQYNRkLYwnWWcCO0BtqTBSi1NI3GhdLdoyk0NIKC6NG4WXwn",
access_token = "2438035310-vbjwfTLJsxdqKjjQkujP6suc1MbTgvZha6Ov3u4",
access_secret = "NoB0NDkf1B8k8xCNnpXmaXn4QwtQrbxFsAmna7mmdfyOE")
file <- read.csv('all_tweets.csv')
file <- read.csv()
file <- read.csv(./Desktop/Github/CSE487/'all_tweet.csv')
file <- read.csv(/Desktop/Github/CSE487/'all_tweet.csv')
file <- read.csv("./Desktop/Github/CSE487/'all_tweet.csv'")
file <- read.csv("./Desktop/Github/CSE487/'add_coord.csv'")
file <- read.csv("./Desktop/Github/CSE487/add_coord.csv")
file <- read.csv("./Desktop/GitHub/CSE487/add_coord.csv")
file <- read.csv("./Desktop/GitHub/CSE487/add_coord.csv")
file <- read.csv("./Desktop/GitHub/CSE487/add_coord.csv")
file <- read.csv("./Desktop/GitHub/CSE487/add_coord.csv")
file <-  data.frame(file$text, file$place_full_name, file$geo_coords, file$coords_coords)
library(rtweet)
file <- read.csv(file = "./Desktop/GitHub/CSE487/add_coord.csv")
file <- read.csv(file = "./Desktop/GitHub/CSE487/add_coord.csv")
file <- read.csv(file = "./Desktop/GitHub/CSE487/add_coord.csv")
library(rtweet)
library(dplyr)
library(stringr)
library(maps)
library(ggplot2)
file <- read.csv(file = "./Desktop/GitHub/CSE487/add_coord.csv")
part3<-read.csv("./Desktop/GitHub/CSE487/add_coord.csv")
part3<-read.csv("/Desktop/GitHub/CSE487/add_coord.csv")
part3<-read.csv("/Desktop/GitHub/CSE487/add_coord.csv")
part3<-read.csv("./Desktop/GitHub/CSE487/add_coord.csv")
part3<-read.csv("./add_coord.csv")
file<-read.csv("./add_coord.csv")
file <-  data.frame(file$text, file$place_full_name, file$geo_coords, file$coords_coords)
#filter duplicate
filter_duplicate <- unique(file)
#filter rt
filter_rt <- filter_duplicate[grep("RT", filter_duplicate$file.text, invert = TRUE) , ]
#filter coordinate
filter_coordinate <- dplyr::filter(filter_rt, filter_rt$file.coords_coords != 'c(Na, Na)')
save_as_csv(filter_coordinate, "map_coordinate.csv" , prepend_ids = TRUE, na = "",
fileEncoding = "UTF-8")
usmap_data <- read.csv('map_coordinate.csv')
usmap_data <- read.csv('map_coordinate.csv')
View(usmap_data)
q4_heatMap<-read.csv(file = "./Desktop/487/part2/q4_heatmap.csv",stringsAsFactors = FALSE)
q4_heatMap<-read.csv(file = "./Desktop/487/part2/q4_heatmap.csv",stringsAsFactors = FALSE)
View(usmap_data)
usmap_data <- read.csv('./part3_data.csv')
head(usmap_data)
View(usmap_data)
table(usmap_data)
table(usmap_data$region)
# data clean
regionCount <- table(usmap_data$region)
regionCount
data.frame(regionCount)
regionData <- data.frame(regionCount)
regionData
View(regionData)
# Plot
(usHeatMap <- ggplot(data = regionData) +
geom_polygon(aes(x = long, y = lat, fill = regionData$Freq, group = group)) +
coord_fixed(1.3) +
labs(title = "2018-19 Influenza Season Week 4",
x = "Longitude", y="Latitude", color="Heat level"))
View(regionData)
regionData <- colnames(regionData)[1] <- "region"
# data clean
regionCount <- table(usmap_data$region)
regionData <- data.frame(regionCount)
regionData <- colnames(regionData)[1] <- "region"
# data clean
regionCount <- table(usmap_data$region)
regionData <- data.frame(regionCount)
colnames(regionData) <- c("region","freq")
merge(usmap_data,regionData,region)
# Plot
(usHeatMap <- ggplot(data = c(usmap_data,regionData)) +
geom_polygon(aes(x = usmap_data$long, y = usmap_data$lat, fill = regionData$Freq, group = group)) +
coord_fixed(1.3) +
labs(title = "2018-19 Influenza Season Week 4",
x = "Longitude", y="Latitude", color="Heat level"))
merge(usmap_data,regionData)
# Plot
(usHeatMap <- ggplot(data = mergedData) +
geom_polygon(aes(x = long, y = lat, fill = freq, group = group)) +
coord_fixed(1.3) +
labs(title = "2018-19 Influenza Season Week 4",
x = "Longitude", y="Latitude", color="Heat level"))
mergedData <- merge(usmap_data,regionData)
# Plot
(usHeatMap <- ggplot(data = mergedData) +
geom_polygon(aes(x = long, y = lat, fill = freq, group = group)) +
coord_fixed(1.3) +
labs(title = "2018-19 Influenza Season Week 4",
x = "Longitude", y="Latitude", color="Heat level"))
head(mergedData)
View(mergedData)
# Plot
(usHeatMap <- ggplot(data = mergedData) +
geom_polygon(aes(x = long, y = lad, fill = freq, group = group)) +
coord_fixed(1.3) +
labs(title = "2018-19 Influenza Season Week 4",
x = "Longitude", y="Latitude", color="Heat level"))
# Get all states data
all_states <- map_data("state")
head(all_states)
finalData <- merge(mergedData,all_states,by="region")
# Plot
(usHeatMap <- ggplot(data = finalData) +
geom_polygon(aes(x = long, y = lad, fill = freq, group = group)) +
coord_fixed(1.3) +
labs(title = "2018-19 Influenza Season Week 4",
x = "Longitude", y="Latitude", color="Heat level"))
finalData
View(finalData)
mergedData <- merge(usmap_data,regionData)
finalData <- merge(mergedData,all_states,by="region")
head(finalData)
View(finalData)
head(regionData)
finalData <- merge(regionData,all_states,by="region")
head(finalData)
View(finalData)
all_states
head(regionData)
regions <- tolower(regionCount$region)
head(regionCount)
regions <- tolower(regionData$region)
regions
lowerRegionFreq <- data.frame(regions,regionData$freq)
finalData <- merge(lowerRegionFreq,all_states,by="region")
head(lowerRegionFreq)
region <- tolower(regionData$region)
lowerRegionFreq <- data.frame(region,regionData$freq)
finalData <- merge(lowerRegionFreq,all_states,by="region")
View(finalData)
# Plot
(usHeatMap <- ggplot(data = finalData) +
geom_polygon(aes(x = long, y = lad, fill = freq, group = group)) +
coord_fixed(1.3) +
labs(title = "2018-19 Influenza Season Week 4",
x = "Longitude", y="Latitude", color="Heat level"))
# Plot
(usHeatMap <- ggplot(data = finalData) +
geom_polygon(aes(x = long, y = lat, fill = freq, group = group)) +
coord_fixed(1.3) +
labs(title = "2018-19 Influenza Season Week 4",
x = "Longitude", y="Latitude", color="Heat level"))
# Plot
(usHeatMap <- ggplot(data = finalData) +
geom_polygon(aes(x = long, y = lat, fill = regionData.freq, group = group)) +
coord_fixed(1.3) +
labs(title = "2018-19 Influenza Season Week 4",
x = "Longitude", y="Latitude", color="Heat level"))
# Plot
(usHeatMap <- ggplot(data = finalData) +
geom_polygon(aes(x = long, y = lat, fill = regionData.freq, group = group)) +
coord_fixed(1.3) +
labs(title = "Tweets about flu",
x = "Longitude", y="Latitude", fill="regionData.freq"))
# Plot
(usHeatMap <- ggplot(data = finalData) +
geom_polygon(aes(x = long, y = lat, fill = regionData.freq, group = group)) +
coord_fixed(1.3) +
labs(title = "Tweets about flu",
x = "Longitude", y="Latitude"))
usHeatMap + guides(fill=guide_legend(title="Tweets amount"))
usmap_data <- read.csv('./finally.csv')
# Get all states data
all_states <- map_data("state")
# data clean
regionCount <- table(usmap_data$region)
regionData <- data.frame(regionCount)
library(rtweet)
library(dplyr)
library(stringr)
library(tidyverse)
library(maps)
library(tidyr)
usmap_data <- read.csv('./finally.csv')
# Get all states data
all_states <- map_data("state")
# data clean
regionCount <- table(usmap_data$region)
regionData <- data.frame(regionCount)
colnames(regionData) <- c("region","freq")
region <- tolower(regionData$region)
lowerRegionFreq <- data.frame(region,regionData$freq)
finalData <- merge(lowerRegionFreq,all_states,by="region")
# Plot
(usHeatMap <- ggplot(data = finalData) +
geom_polygon(aes(x = long, y = lat, fill = regionData.freq, group = group)) +
coord_fixed(1.3) +
labs(title = "Tweets about flu",
x = "Longitude", y="Latitude"))
usHeatMap + guides(fill=guide_legend(title="Tweets amount"))
library(rtweet)
library(dplyr)
library(stringr)
library(tidyverse)
library(maps)
library(tidyr)
create_token(
app = "www.twitter.com",
consumer_key = "BoWXRggutLO4NqoCNv3GAPR06",
consumer_secret = "oYgQYNRkLYwnWWcCO0BtqTBSi1NI3GhdLdoyk0NIKC6NG4WXwn",
access_token = "2438035310-vbjwfTLJsxdqKjjQkujP6suc1MbTgvZha6Ov3u4",
access_secret = "NoB0NDkf1B8k8xCNnpXmaXn4QwtQrbxFsAmna7mmdfyOE")
since <- "2019-2-25"
until <- "2019-3-05"
search_query_more = "#cough OR #influeza OR #fever OR #vaccines OR #health OR #sick OR #flushot"
search_query = "#flu OR # cough OR #H3N2 OR #fluseason OR #fightflu "
even_more_query = "#swineflu OR #CDC OR #fatigue OR #sorethroat OR #headache OR #sneeze OR #flu2019"
lastday_even_more <- search_tweets(
q= search_query, n = 10000, type="recent",include_rts= TRUE,
geocode = lookup_coords("usa")
)
